{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "712992a9",
   "metadata": {},
   "source": [
    "## RAPADA PARTNERS - CASE STUDY - Madrid´s Real Estate Market"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7265e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.ticker as ticker\n",
    "import folium\n",
    "from folium.plugins import MarkerCluster\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976cac09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dataset\n",
    "url = \"technical_interview.parquet\"\n",
    "df = pd.read_parquet(url)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a49fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original = df.copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90878d79",
   "metadata": {},
   "source": [
    "# 1. Initial data exploration, cleaning and handling missing or anomalous values\n",
    "##### Before performing any in depth analysis, we begin by understandig de dataset structure and addresing missing values or outliers that could affect our results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81b66b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('----------------------------------------------------------------------------------------------------')\n",
    "print('Dataset Shape (rows, columns):')\n",
    "print(df.shape)\n",
    "\n",
    "print('\\n ----------------------------------------------------------------------------------------------------')\n",
    "print('Column Names')\n",
    "print(df.columns)\n",
    "\n",
    "print('\\n ----------------------------------------------------------------------------------------------------')\n",
    "print('Data Types and non-null counts')\n",
    "print(df.info())\n",
    "\n",
    "print('\\n ----------------------------------------------------------------------------------------------------')\n",
    "print('Missing Values per column (sorted in descending order):')\n",
    "missing_values = df.isnull().sum().sort_values(ascending=False)\n",
    "print(missing_values[missing_values > 0])\n",
    "\n",
    "\n",
    "print('\\n ----------------------------------------------------------------------------------------------------')\n",
    "print('\\n General Statistics (numerical variables)')\n",
    "print(df.describe().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0e1c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"is_exterior\"] = df[\"is_exterior\"].astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5233e738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary Table including types and nulls\n",
    "summary_table = pd.DataFrame(df.dtypes, columns=['Type']).T\n",
    "\n",
    "missing_count = pd.DataFrame(df.isnull().sum()).T\n",
    "missing_count.index = ['Missing Values (nb)']\n",
    "\n",
    "missing_percentage = pd.DataFrame(df.isnull().mean() * 100).T\n",
    "missing_percentage.index = ['Missing Values (%)']\n",
    "\n",
    "\n",
    "summary_table = pd.concat([summary_table, missing_count, missing_percentage])\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "print('Summary Table')\n",
    "display(summary_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ada18b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique values and counts for location-related columns\n",
    "print(\"\\n Unique values in 'state':\")\n",
    "print(f\"{df['state'].nunique()} unique values -> {df['state'].unique()}\")\n",
    "print(\"Counts:\\n\", \"Column:\", df['state'].value_counts())\n",
    "\n",
    "print(\"\\n Unique values in 'province':\")\n",
    "print(f\"{df['province'].nunique()} unique values -> {df['province'].unique()}\")\n",
    "print(\"Counts:\\n\", \"Column:\", df['province'].value_counts())\n",
    "\n",
    "print(\"\\n Unique values in 'country_code':\")\n",
    "print(f\"{df['country_code'].nunique()} unique value -> {df['country_code'].unique()}\")\n",
    "print(\"Counts:\\n\", \"Column:\", df['country_code'].value_counts())\n",
    "\n",
    "# Since the goal is to analyze the Madrid real estate market, we filter out properties outside Community of Madrid, keeping only those within the province of Madrid.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d03b1a3",
   "metadata": {},
   "source": [
    "### 1.1 Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c820c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = pd.DataFrame({\n",
    "    \"Missing values\": df.isnull().sum(),\n",
    "    \"Missing (%)\": df.isnull().mean() * 100,\n",
    "    \"Data type\": df.dtypes\n",
    "})\n",
    "\n",
    "missing_values = missing_values[missing_values[\"Missing values\"] > 0].sort_values(\"Missing (%)\", ascending=False)\n",
    "display(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f2f718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the missing values of n_rooms and n_baths it´s related to the property_type\n",
    "\n",
    "##############################ROOMS###############################################\n",
    "rooms = df[df[\"n_rooms\"].isnull()]\n",
    "print(f\"Number of properties with missing n_rooms: {rooms.shape[0]}\")\n",
    "print(\"\\nProperty types with missing n_rooms:\")\n",
    "print(rooms[\"property_type\"].value_counts())\n",
    "##############################BATHS###############################################\n",
    "baths = df[df[\"n_baths\"].isnull()]\n",
    "print(f\"\\nNumber of properties with missing n_baths: {baths.shape[0]}\")\n",
    "print(\"\\nProperty types with missing n_baths:\")\n",
    "print(baths[\"property_type\"].value_counts())\n",
    "\n",
    "# Conclusion: missing values of rooms and baths were mostly found in non-residential properties where these features are irrelevant.\n",
    "rooms_baths = [\"n_rooms\", \"n_baths\"]\n",
    "df[rooms_baths] = df[rooms_baths].fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5768cf94",
   "metadata": {},
   "outputs": [],
   "source": [
    "area_price = [\"area\", \"price\"]\n",
    "df.dropna(subset=area_price, inplace=True)\n",
    "\n",
    "boolean_columns = [\n",
    "    \"has_elevator\", \"has_terrace\", \"is_exterior\", \"has_swimming_pool\",\n",
    "    \"has_parking\", \"has_garden\", \"has_energy_certificate\", \"has_floorplan\",\n",
    "    \"has_virtual_tour\", \"approximate_location\"\n",
    "]\n",
    "df[boolean_columns] = df[boolean_columns].fillna(False)\n",
    "\n",
    "\n",
    "categorical_columns = [\"property_state\", \"district\", \"quarter\", \"province\", \"postcode\"]\n",
    "df[categorical_columns] = df[categorical_columns].fillna(\"Unknown\")\n",
    "\n",
    "print(\"Remaining missing values after cleaning:\")\n",
    "print(df.isnull().sum()[df.isnull().sum() > 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4ec2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "floor_missing = df[df[\"floor\"].isnull()]\n",
    "\n",
    "print(f\"Total properties with missing 'floor': {floor_missing.shape[0]}\\n\")\n",
    "print(\"Property types with missing 'floor':\")\n",
    "print(floor_missing[\"property_type\"].value_counts())\n",
    "\n",
    "# Checking whether the missing values make sense before making conclusions\n",
    "keywords = [\"chalet\", \"adosado\", \"casa\"]\n",
    "for word in keywords:\n",
    "    count = floor_missing[\"ad_description\"].str.contains(word, case=False, na=False).sum()\n",
    "    print(f\"Occurrences of '{word}' in ad_description: {count}\")\n",
    "\n",
    "\n",
    "df[\"floor\"] = df[\"floor\"].replace(0, np.nan)\n",
    "\n",
    "df[\"has_floor_info\"] = df[\"floor\"].notnull().astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c44b61c",
   "metadata": {},
   "source": [
    "### 1.2 Negative values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de0c19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_values = df[\n",
    "    (df[\"price\"] <= 0) |\n",
    "    (df[\"area\"] <= 0) |\n",
    "    (df[\"n_rooms\"] < 0) |\n",
    "    (df[\"n_baths\"] < 0) |\n",
    "    (df[\"floor\"] < 0) |\n",
    "    (df[\"price_down_from\"] < 0)\n",
    "]\n",
    "\n",
    "# We will handle this values following:\n",
    "#  price and area <= 0 → Drop values, probably invalid data \n",
    "df = df[(df[\"price\"] > 0) & (df[\"area\"] > 0)]\n",
    "\n",
    "#  n_rooms and n_baths < 0 → Set to 0 probably missing/incorrect data\n",
    "df.loc[df[\"n_rooms\"] < 0, \"n_rooms\"] = None\n",
    "df.loc[df[\"n_baths\"] < 0, \"n_baths\"] = None\n",
    "\n",
    "#  floor < 0 → Set to -1 (we will use -1 for \"not applicable\" floor)\n",
    "df.loc[df[\"floor\"] < 0, \"floor\"] = 0\n",
    "\n",
    "#  price_down_from < 0 → Set to NaN \n",
    "df.loc[df[\"price_down_from\"] < 0, \"price_down_from\"] = None\n",
    "\n",
    "print(f\"Remaining records after cleaning: {df.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e095586",
   "metadata": {},
   "source": [
    "### After this analysis we reduce the dataset to include only the relevant information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5394e371",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "final_columns = [\n",
    "    \"property_type\", \"transaction_type\", \"n_rooms\", \"n_baths\", \"area\", \"floor\",\"has_elevator\", \"has_terrace\", \"is_exterior\",\n",
    "    \"has_swimming_pool\",\"has_parking\", \"has_garden\",\"energy_certificate_consumption\", \"has_energy_certificate\",\n",
    "    \"has_floorplan\", \"property_state\",\"latitude\", \"longitude\" , \"province\", \"city\",\"district\",\"quarter\",\"price_down_from\", \"price\"\n",
    "]\n",
    "df= df[final_columns]\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab226a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary Table including types and nulls\n",
    "summary_table = pd.DataFrame(df.dtypes, columns=['Type']).T\n",
    "\n",
    "missing_count = pd.DataFrame(df.isnull().sum()).T\n",
    "missing_count.index = ['Missing Values (nb)']\n",
    "\n",
    "missing_percentage = pd.DataFrame(df.isnull().mean() * 100).T\n",
    "missing_percentage.index = ['Missing Values (%)']\n",
    "\n",
    "\n",
    "summary_table = pd.concat([summary_table, missing_count, missing_percentage])\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "print('Summary Table')\n",
    "display(summary_table)\n",
    "\n",
    "df[\"is_exterior\"] = df[\"is_exterior\"].astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fe76c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    print(f\"\\ Column: {col}\")\n",
    "    print(df[col].value_counts(dropna=False)) \n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3095a00",
   "metadata": {},
   "source": [
    "### 1.3 Outliers\n",
    "For the porpuse of the exploratory analysis, we will remove extreme outliers in price and area to avoid distorsions in following visualizations and summary statistics. However we will keep a copy of the original dataset for later modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e6a26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Price summary:\")\n",
    "print(df[\"price\"].describe())\n",
    "print(\"\\nArea summary:\")\n",
    "print(df[\"area\"].describe())\n",
    "print(\"\\nPrice per m² summary:\")\n",
    "df[\"price_per_m2\"] = df[\"price\"] / df[\"area\"]\n",
    "print(df[\"price_per_m2\"].describe())\n",
    "\n",
    "# Visualizing the distribution before cleaning\n",
    "fig, axs = plt.subplots(1, 3, figsize=(18, 5))\n",
    "sns.boxplot(x=df[\"price\"], ax=axs[0])\n",
    "axs[0].set_title(\"Boxplot of price\")\n",
    "sns.boxplot(x=df[\"area\"], ax=axs[1])\n",
    "axs[1].set_title(\"Boxplot of area\")\n",
    "sns.boxplot(x=df[\"price_per_m2\"], ax=axs[2])\n",
    "axs[2].set_title(\"Boxplot of price per m²\")\n",
    "plt.show()\n",
    "\n",
    "df_original = df.copy()\n",
    "\n",
    "# Remove outliers using the IQR Method\n",
    "def remove_outliers(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower = Q1 - 1.5 * IQR\n",
    "    upper = Q3 + 1.5 * IQR\n",
    "    print(f\"Filtering outliers in {column}: keeping values between {lower:.2f} and {upper:.2f}\")\n",
    "    return df[(df[column] >= lower) & (df[column] <= upper)]\n",
    "\n",
    "df = remove_outliers(df, \"price\")\n",
    "df = remove_outliers(df, \"area\")\n",
    "df = remove_outliers(df, \"price_per_m2\")\n",
    "\n",
    "# Visualizing the distribution after cleaning\n",
    "fig, axs = plt.subplots(1, 3, figsize=(18, 5))\n",
    "sns.boxplot(x=df[\"price\"], ax=axs[0])\n",
    "axs[0].set_title(\"Boxplot of price (cleaned)\")\n",
    "sns.boxplot(x=df[\"area\"], ax=axs[1])\n",
    "axs[1].set_title(\"Boxplot of area (cleaned)\")\n",
    "sns.boxplot(x=df[\"price_per_m2\"], ax=axs[2])\n",
    "axs[2].set_title(\"Boxplot of price per m² (cleaned)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304b7421",
   "metadata": {},
   "outputs": [],
   "source": [
    "## NUMERICAL VALUES\n",
    "num_cols = df.select_dtypes(include='number').columns\n",
    "df[num_cols].describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0b951a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
    "\n",
    "# Price Histogram, to visualize the price distribution\n",
    "sns.histplot(df['price'], kde=True, bins=30, color='blue', ax=axes[0])\n",
    "axes[0].set_title('Price Distribution')\n",
    "axes[0].set_xlabel('Price (€)')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "\n",
    "# Are Histogram, to visualize the area distribution\n",
    "sns.histplot(df['area'], kde=True, bins=30, color='orange', ax=axes[1])\n",
    "axes[1].set_title('Area Distribution')\n",
    "axes[1].set_xlabel('Área (m²)')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "\n",
    "df['price_per_m2'] = df['price'] / df['area']\n",
    "\n",
    "# Price per m2 distribution\n",
    "sns.histplot(df['price_per_m2'], kde=True, bins=30, color='green', ax=axes[2])\n",
    "axes[2].set_title('Price per m2 Distribution')\n",
    "axes[2].set_xlabel('Price per m² (€)')\n",
    "axes[2].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6c0c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical columns\n",
    "num_cols = df.select_dtypes(include=[\"int\", \"float\"]).columns\n",
    "\n",
    "# Correlation matrix\n",
    "corr_matrix = df[num_cols].corr()\n",
    "\n",
    "# heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\", square=True)\n",
    "plt.title(\"Correlation matrix (numerical variables)\")\n",
    "plt.show()\n",
    "\n",
    "sorted_corr = corr_matrix.abs().unstack().sort_values(ascending=False)\n",
    "sorted_corr = sorted_corr[(sorted_corr < 1.0)]\n",
    "\n",
    "# Strong correlations \n",
    "strong_corr = sorted_corr[sorted_corr >= 0.7]\n",
    "print(\"Strong correlations (rate ≥ 0.7):\\n\", strong_corr)\n",
    "\n",
    "# Medium correlations (rate between 0.3 and 0.7)\n",
    "medium_corr = sorted_corr[(sorted_corr >= 0.3) & (sorted_corr < 0.7)]\n",
    "print(\"\\n Medium correlations (0.3 ≤ rate < 0.7):\\n\", medium_corr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45043dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "district_price = df.groupby(\"district\")[\"price\"].mean().sort_values(ascending=False)\n",
    "\n",
    "top_districts = district_price.head(15)\n",
    "bottom_districts = district_price.tail(15)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 8), sharex=False)\n",
    "\n",
    "sns.barplot(x=top_districts.values, y=top_districts.index,hue=top_districts.index, palette=\"flare\", ax=axes[0])\n",
    "axes[0].set_title(\"Top 20 Most Expensive Districts\", fontsize=14)\n",
    "axes[0].set_xlabel(\"Average price(€)\")\n",
    "axes[0].set_ylabel(\"District\")\n",
    "axes[0].xaxis.set_major_formatter(ticker.FuncFormatter(lambda x, _: f\"{int(x):,}\".replace(\",\", \".\")))\n",
    "\n",
    "sns.barplot(x=bottom_districts.values, y=bottom_districts.index,hue=bottom_districts, palette=\"crest\", ax=axes[1])\n",
    "axes[1].set_title(\"Top 20 Least Expensive Districts\", fontsize=14)\n",
    "axes[1].set_xlabel(\"Average price(€)\")\n",
    "axes[1].set_ylabel(\"District\")\n",
    "axes[1].xaxis.set_major_formatter(ticker.FuncFormatter(lambda x, _: f\"{int(x):,}\".replace(\",\", \".\")))\n",
    "\n",
    "plt.suptitle(\"Comparison of Average Property Prices by District\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8f50bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"price_per_m2\"] = df[\"price\"] / df[\"area\"]\n",
    "\n",
    "district_price = df.groupby(\"district\")[\"price_per_m2\"].mean().sort_values(ascending=False)\n",
    "\n",
    "\n",
    "top_districts = district_price.head(15)\n",
    "bottom_districts = district_price.tail(15)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 8), sharex=False)\n",
    "\n",
    "sns.barplot(x=top_districts.values, y=top_districts.index,hue=top_districts.index, palette=\"flare\", ax=axes[0])\n",
    "axes[0].set_title(\"Top 20 Most Expensive Districts\", fontsize=14)\n",
    "axes[0].set_xlabel(\"Average price per m2(€)\")\n",
    "axes[0].set_ylabel(\"District\")\n",
    "axes[0].xaxis.set_major_formatter(ticker.FuncFormatter(lambda x, _: f\"{int(x):,}\".replace(\",\", \".\")))\n",
    "\n",
    "sns.barplot(x=bottom_districts.values, y=bottom_districts.index,hue=bottom_districts, palette=\"crest\", ax=axes[1])\n",
    "axes[1].set_title(\"Top 20 Least Expensive Districts\", fontsize=14)\n",
    "axes[1].set_xlabel(\"Average price per m2(€)\")\n",
    "axes[1].set_ylabel(\"\")\n",
    "axes[1].xaxis.set_major_formatter(ticker.FuncFormatter(lambda x, _: f\"{int(x):,}\".replace(\",\", \".\")))\n",
    "\n",
    "plt.suptitle(\"Comparison of Average Property Prices per m2 by District\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de2499d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a base map centered on Madrid\n",
    "madrid_map = folium.Map(location=[40.4168, -3.7038], zoom_start=11, tiles=\"CartoDB positron\")\n",
    "\n",
    "# Create a marker cluster to group nearby points\n",
    "marker_cluster = MarkerCluster().add_to(madrid_map)\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    folium.CircleMarker(\n",
    "        location=[row[\"latitude\"], row[\"longitude\"]],\n",
    "        radius=3,\n",
    "        color=\"blue\",\n",
    "        fill=True,\n",
    "        fill_color=\"blue\",\n",
    "        fill_opacity=0.5,\n",
    "        popup=f\"Price: €{row['price']:,}\\nType: {row['property_type']}\\nDistrict: {row['district']}\"\n",
    "    ).add_to(marker_cluster)\n",
    "\n",
    "\n",
    "madrid_map\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d1fcbf",
   "metadata": {},
   "source": [
    "\n",
    "\"\"\"\n",
    "# Modeling Approach: separating Sales and Rentals\n",
    "\n",
    "To build accurate predictive models, we separate the dataset into **sales** (transaction_type = 'buy' or 'venta') and **rentals** (transaction_type = 'rent' or 'alquiler'). \n",
    "This distinction is important because the dynamics of these two markets behave differently: \n",
    "- Properties for sale and those for rent have different price ranges and influencing factors.\n",
    "- Mixing them in a single model could lead to poor predictions and misleading insights.\n",
    "\n",
    "We will train two independent models:\n",
    "1. **Sales Model**: Predicts the market price of properties for sale, allowing to detect underpriced investment opportunities.\n",
    "2. **Rentals Model**: Predicts rental prices and helps estimate potential gross rental yields to identify high-return areas.\n",
    "\n",
    "This separation ensures that the analysis captures the unique characteristics of each market and provides actionable insights for our investors, Rapada Partners.\n",
    "\n",
    "We will use a Random Forest Regressor as our predictive model:\n",
    "1. **Non-linear relationships and interaction effects.**: Random Forest can handle complex, non-linear relationships between features (e.g., area, number of rooms, amenities) and property prices, which are common in real estate markets.\n",
    "2. **Robustness to outliers**: It is less sensitive to outliers in the data compared to linear models, which is important given the presence of high-value luxury properties.\n",
    "3. **Feature importance**: Random Forest provides a natural way to evaluate the relative importance of each feature in determining prices, helping to interpret results and support investment decisions.\n",
    "4. **No need for heavy preprocessing**: It does not require extensive normalization or scaling of numerical features. Also they do not require as much pre-processing as other models.\n",
    "5. **Proven performance**: Ensemble tree methods as a Random Forest are widely used in real estate price prediction for their reliability and accuracy.\n",
    "\n",
    "\n",
    "We train two independent Random Forest models: one for predicting sales prices and another for rental prices. Using these predictions:\n",
    "- For **sales**, we compute the difference between predicted and actual prices (*price gap*) to identify **underpriced properties**.\n",
    "- For **rentals**, we estimate potential annual income and calculate the **gross rental yield (%)**, allowing us to identify districts with higher investment returns.\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943d1294",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"transaction_type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb83e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the dataset into sales and rentals\n",
    "df_sales = df[df[\"transaction_type\"].isin([\"buy\", \"venta\"])].copy()\n",
    "df_rentals = df[df[\"transaction_type\"].isin([\"rent\", \"alquiler\"])].copy()\n",
    "\n",
    "print(f\"Sales dataset shape: {df_sales.shape}\")\n",
    "print(f\"Rentals dataset shape: {df_rentals.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e9bf6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the sales dataset\n",
    "features = [\n",
    "    \"n_rooms\", \"n_baths\", \"area\", \"floor\", \"has_elevator\", \"has_terrace\", \"is_exterior\",\n",
    "    \"has_swimming_pool\", \"has_parking\", \"has_garden\", \"has_energy_certificate\",\n",
    "    \"has_floorplan\", \"is_discounted\", \"is_luxury\"\n",
    "]\n",
    "df_sales_model = df_sales[features + [\"district\", \"price\"]].copy()\n",
    "df_sales_model = pd.get_dummies(df_sales_model, columns=[\"district\"], drop_first=True)\n",
    "\n",
    "X_sales = df_sales_model.drop(columns=[\"price\"])\n",
    "y_sales = df_sales_model[\"price\"]\n",
    "\n",
    "# Split data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_s, X_test_s, y_train_s, y_test_s = train_test_split(X_sales, y_sales, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Random Forest model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model_sales = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "model_sales.fit(X_train_s, y_train_s)\n",
    "\n",
    "# Evaluate\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "y_pred_s = model_sales.predict(X_test_s)\n",
    "print(f\"Sales Model - MAE: {mean_absolute_error(y_test_s, y_pred_s):,.0f} €\")\n",
    "print(f\"Sales Model - R²: {r2_score(y_test_s, y_pred_s):.2f}\")\n",
    "\n",
    "# Predict prices and compute price gaps\n",
    "df_sales[\"predicted_price\"] = model_sales.predict(X_sales)\n",
    "df_sales[\"price_gap\"] = df_sales[\"predicted_price\"] - df_sales[\"price\"]\n",
    "df_sales[\"undervalued\"] = df_sales[\"price_gap\"] > 50_000\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bdef04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the rentals dataset\n",
    "df_rentals_model = df_rentals[features + [\"district\", \"price\"]].copy()\n",
    "df_rentals_model = pd.get_dummies(df_rentals_model, columns=[\"district\"], drop_first=True)\n",
    "\n",
    "X_rentals = df_rentals_model.drop(columns=[\"price\"])\n",
    "y_rentals = df_rentals_model[\"price\"]\n",
    "\n",
    "# Split data\n",
    "X_train_r, X_test_r, y_train_r, y_test_r = train_test_split(X_rentals, y_rentals, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Random Forest model\n",
    "model_rentals = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "model_rentals.fit(X_train_r, y_train_r)\n",
    "\n",
    "# Evaluate\n",
    "y_pred_r = model_rentals.predict(X_test_r)\n",
    "print(f\"Rentals Model - MAE: {mean_absolute_error(y_test_r, y_pred_r):,.0f} €\")\n",
    "print(f\"Rentals Model - R²: {r2_score(y_test_r, y_pred_r):.2f}\")\n",
    "\n",
    "# Predict prices and compute price gaps\n",
    "df_rentals[\"predicted_price\"] = model_rentals.predict(X_rentals)\n",
    "df_rentals[\"price_gap\"] = df_rentals[\"predicted_price\"] - df_rentals[\"price\"]\n",
    "df_rentals[\"undervalued\"] = df_rentals[\"price_gap\"] > 200  # Gap threshold for rentals (e.g. €200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e82c194",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importances(model, X, title, ax=None, color=None):\n",
    "    importances = pd.Series(model.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    importances.head(15).plot(kind=\"barh\", ax=ax, color=color)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"Importance\")\n",
    "    ax.invert_yaxis()\n",
    "    return importances\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "# Sales\n",
    "sales_importances = plot_feature_importances(model_sales, X_sales, \"Top 15 Features for Sales Price Prediction\", ax = axes[0], color='lightblue')\n",
    "\n",
    "# Rents\n",
    "rental_importances = plot_feature_importances(model_rentals, X_rentals, \"Top 15 Features for Rental Price Prediction\", ax =axes[1], color='lightgreen')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe92d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate gross rental yield (%)\n",
    "avg_rent_district = df_rentals.groupby(\"district\")[\"price\"].mean().rename(\"avg_rent_price\")\n",
    "df_sales = df_sales.merge(avg_rent_district, on=\"district\", how=\"left\")\n",
    "df_sales[\"gross_yield_pct\"] = (df_sales[\"avg_rent_price\"] * 12) / df_sales[\"price\"] * 100\n",
    "\n",
    "# Ranking: Districts with most undervalued properties\n",
    "district_opps_sales = df_sales[df_sales[\"undervalued\"]].groupby(\"district\").agg(\n",
    "    n_undervalued=(\"undervalued\", \"sum\"),\n",
    "    avg_price_gap=(\"price_gap\", \"mean\"),\n",
    "    avg_price=(\"price\", \"mean\"),\n",
    "    avg_price_m2=(\"price_per_m2\", \"mean\"),\n",
    "    avg_gross_yield_pct=(\"gross_yield_pct\", \"mean\")\n",
    ").sort_values(by=\"n_undervalued\", ascending=False)\n",
    "\n",
    "print(\"\\nTop 15 districts with most undervalued sales properties:\")\n",
    "display(district_opps_sales.head(15))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f7fbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_districts = district_opps_sales[district_opps_sales.index != \"Unknown\"].head(10).reset_index()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "scatter = plt.scatter(\n",
    "    filtered_districts[\"avg_price_gap\"],\n",
    "    filtered_districts[\"avg_gross_yield_pct\"],\n",
    "    s=filtered_districts[\"n_undervalued\"]*0.5,  \n",
    "    c=filtered_districts[\"avg_gross_yield_pct\"], \n",
    "    cmap=\"coolwarm\", alpha=0.7, edgecolors=\"k\"\n",
    ")\n",
    "\n",
    "for i, txt in enumerate(filtered_districts[\"district\"]):\n",
    "    plt.annotate(txt, (filtered_districts[\"avg_price_gap\"][i], filtered_districts[\"avg_gross_yield_pct\"][i]), fontsize=9, weight='bold')\n",
    "\n",
    "\n",
    "plt.title(\"Undervalued Sales Properties: District Highlights\", fontsize=14, weight=\"bold\")\n",
    "plt.xlabel(\"Average Price Gap (€)\")\n",
    "plt.ylabel(\"Gross Yield (%)\")\n",
    "plt.colorbar(scatter, label=\"Gross Yield (%)\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53ccea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Ranking: Districts with most undervalued rental properties\n",
    "district_opps_rentals = df_rentals[df_rentals[\"undervalued\"]].groupby(\"district\").agg(\n",
    "    n_undervalued=(\"undervalued\", \"sum\"),\n",
    "    avg_price_gap=(\"price_gap\", \"mean\"),\n",
    "    avg_price=(\"price\", \"mean\"),\n",
    "    avg_price_m2=(\"price_per_m2\", \"mean\")\n",
    ").sort_values(by=\"n_undervalued\", ascending=False)\n",
    "\n",
    "print(\"\\nTop 15 districts with most undervalued rental properties:\")\n",
    "display(district_opps_rentals.head(15))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cd0285",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filtered_rentals = district_opps_rentals[district_opps_rentals.index != \"Unknown\"].head(10).reset_index()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "scatter = plt.scatter(\n",
    "    filtered_rentals[\"avg_price_gap\"],\n",
    "    filtered_rentals[\"avg_price_m2\"],\n",
    "    s=filtered_rentals[\"n_undervalued\"]*0.5,  \n",
    "    c=filtered_rentals[\"avg_price_m2\"],  \n",
    "    cmap=\"viridis\", alpha=0.7, edgecolors=\"k\"\n",
    ")\n",
    "\n",
    "for i, txt in enumerate(filtered_rentals[\"district\"]):\n",
    "    plt.annotate(txt, (filtered_rentals[\"avg_price_gap\"][i], filtered_rentals[\"avg_price_m2\"][i]), fontsize=9, weight='bold')\n",
    "\n",
    "\n",
    "plt.title(\"Undervalued Rental Properties: District Highlights\", fontsize=14, weight=\"bold\")\n",
    "plt.xlabel(\"Average Price Gap (€)\")\n",
    "plt.ylabel(\"Average Price per m² (€)\")\n",
    "plt.colorbar(scatter, label=\"Average Price per m² (€)\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa68bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Scatter plot: real vs predicted prices (sales)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test_s, y_pred_s, alpha=0.4, edgecolors=\"k\")\n",
    "plt.plot([y_test_s.min(), y_test_s.max()], [y_test_s.min(), y_test_s.max()], 'r--', lw=2)\n",
    "plt.title(\"Sales Model: Actual vs Predicted Prices\", fontsize=14, weight=\"bold\")\n",
    "plt.xlabel(\"Actual Price (€)\")\n",
    "plt.ylabel(\"Predicted Price (€)\")\n",
    "plt.gca().xaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f\"€{int(x):,}\"))\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
